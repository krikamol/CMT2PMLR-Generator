{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from shutil import copyfile, Error\n",
    "from jinja2 import Environment, FileSystemLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/User/Documents'\n",
    "crp_file  = 'CameraReadyPapers-11-03-2021.xls'\n",
    "crp_sheet = 'AISTATS2021'\n",
    "org_pdf_folder = os.path.abspath('org_pdfs')\n",
    "dest_pdf_folder = os.path.abspath('dest_pdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CMT export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Names</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Primary Contact Author Email</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Files</th>\n",
       "      <th>Q1 (Camera Ready Submission Instruction)</th>\n",
       "      <th>Q2 (Submission Code)</th>\n",
       "      <th>Q3 (Student Author)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>On the Effect of Auxiliary Tasks on Representa...</td>\n",
       "      <td>While auxiliary tasks play a key role in shapi...</td>\n",
       "      <td>Clare Lyle (University of Oxford); Mark Rowlan...</td>\n",
       "      <td>clare.lyle@univ.ox.ac.uk; markrowland@google.c...</td>\n",
       "      <td>markrowland@google.com</td>\n",
       "      <td>AISTATS2021</td>\n",
       "      <td>4-Permission.pdf (1538064 bytes); 4-supp.pdf (...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NDkwN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>LassoNet: Neural Networks with Feature Sparsity</td>\n",
       "      <td>Much work has been done recently to make neura...</td>\n",
       "      <td>Ismael Lemhadri (Stanford University)*; Feng R...</td>\n",
       "      <td>i.lemhadri@gmail.com; fengruan@stanford.edu; t...</td>\n",
       "      <td>i.lemhadri@gmail.com</td>\n",
       "      <td>AISTATS2021</td>\n",
       "      <td>6-Permission.pdf (374474 bytes); 6.pdf (120698...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>OWEwZ</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Projection-Free Optimization on Uniformly Conv...</td>\n",
       "      <td>The Frank-Wolfe method solves smooth constrain...</td>\n",
       "      <td>Thomas Kerdreux (INRIA/ ENS)*; Alexandre d'Asp...</td>\n",
       "      <td>thomaskerdreux@gmail.com; aspremon@ens.fr; pok...</td>\n",
       "      <td>thomaskerdreux@gmail.com</td>\n",
       "      <td>AISTATS2021</td>\n",
       "      <td>7-supp.pdf (314961 bytes); 7.pdf (553162 bytes...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>ODc2Y</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Differentiable Greedy Algorithm for Monotone S...</td>\n",
       "      <td>Motivated by, e.g., sensitivity analysis and e...</td>\n",
       "      <td>Shinsaku Sakaue (The University of Tokyo)*</td>\n",
       "      <td>sakaue@mist.i.u-tokyo.ac.jp</td>\n",
       "      <td>sakaue@mist.i.u-tokyo.ac.jp</td>\n",
       "      <td>AISTATS2021</td>\n",
       "      <td>8.pdf (767828 bytes); 8-supp.pdf (912627 bytes...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>ZWE1N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Graphical Normalizing Flows</td>\n",
       "      <td>Normalizing flows model complex probability di...</td>\n",
       "      <td>Antoine Wehenkel (University of Liège)*; Gille...</td>\n",
       "      <td>antoine.wehenkel@uliege.be; g.louppe@uliege.be</td>\n",
       "      <td>antoine.wehenkel@uliege.be</td>\n",
       "      <td>AISTATS2021</td>\n",
       "      <td>12-supp.pdf (1132933 bytes); 12.pdf (1193165 b...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NGEzM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paper ID                                        Paper Title  \\\n",
       "0         4  On the Effect of Auxiliary Tasks on Representa...   \n",
       "1         6    LassoNet: Neural Networks with Feature Sparsity   \n",
       "2         7  Projection-Free Optimization on Uniformly Conv...   \n",
       "3         8  Differentiable Greedy Algorithm for Monotone S...   \n",
       "4        12                        Graphical Normalizing Flows   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  While auxiliary tasks play a key role in shapi...   \n",
       "1  Much work has been done recently to make neura...   \n",
       "2  The Frank-Wolfe method solves smooth constrain...   \n",
       "3  Motivated by, e.g., sensitivity analysis and e...   \n",
       "4  Normalizing flows model complex probability di...   \n",
       "\n",
       "                                        Author Names  \\\n",
       "0  Clare Lyle (University of Oxford); Mark Rowlan...   \n",
       "1  Ismael Lemhadri (Stanford University)*; Feng R...   \n",
       "2  Thomas Kerdreux (INRIA/ ENS)*; Alexandre d'Asp...   \n",
       "3         Shinsaku Sakaue (The University of Tokyo)*   \n",
       "4  Antoine Wehenkel (University of Liège)*; Gille...   \n",
       "\n",
       "                                       Author Emails  \\\n",
       "0  clare.lyle@univ.ox.ac.uk; markrowland@google.c...   \n",
       "1  i.lemhadri@gmail.com; fengruan@stanford.edu; t...   \n",
       "2  thomaskerdreux@gmail.com; aspremon@ens.fr; pok...   \n",
       "3                        sakaue@mist.i.u-tokyo.ac.jp   \n",
       "4     antoine.wehenkel@uliege.be; g.louppe@uliege.be   \n",
       "\n",
       "  Primary Contact Author Email   Track Name  \\\n",
       "0       markrowland@google.com  AISTATS2021   \n",
       "1         i.lemhadri@gmail.com  AISTATS2021   \n",
       "2     thomaskerdreux@gmail.com  AISTATS2021   \n",
       "3  sakaue@mist.i.u-tokyo.ac.jp  AISTATS2021   \n",
       "4   antoine.wehenkel@uliege.be  AISTATS2021   \n",
       "\n",
       "                                               Files  \\\n",
       "0  4-Permission.pdf (1538064 bytes); 4-supp.pdf (...   \n",
       "1  6-Permission.pdf (374474 bytes); 6.pdf (120698...   \n",
       "2  7-supp.pdf (314961 bytes); 7.pdf (553162 bytes...   \n",
       "3  8.pdf (767828 bytes); 8-supp.pdf (912627 bytes...   \n",
       "4  12-supp.pdf (1132933 bytes); 12.pdf (1193165 b...   \n",
       "\n",
       "  Q1 (Camera Ready Submission Instruction) Q2 (Submission Code)  \\\n",
       "0                       Agreement accepted                NDkwN   \n",
       "1                       Agreement accepted                OWEwZ   \n",
       "2                       Agreement accepted                ODc2Y   \n",
       "3                       Agreement accepted                ZWE1N   \n",
       "4                       Agreement accepted                NGEzM   \n",
       "\n",
       "  Q3 (Student Author)  \n",
       "0                  No  \n",
       "1                 Yes  \n",
       "2                  No  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRP = pd.read_excel(crp_file,sheet_name=crp_sheet)\n",
    "CRP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some basic validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q3 (Student Author)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Q3 (Student Author)\n",
       "0                    No\n",
       "1                   Yes\n",
       "2                    No\n",
       "3                   NaN\n",
       "4                   NaN\n",
       "5                   NaN\n",
       "6                   Yes\n",
       "7                   Yes\n",
       "8                   Yes\n",
       "9                    No\n",
       "10                   No\n",
       "11                  Yes\n",
       "12                   No\n",
       "13                   No\n",
       "14                  Yes\n",
       "15                  NaN\n",
       "16                   No\n",
       "17                   No\n",
       "18                  Yes\n",
       "19                  Yes\n",
       "20                  Yes\n",
       "21                  Yes\n",
       "22                  Yes\n",
       "23                  Yes\n",
       "24                  Yes\n",
       "25                  NaN\n",
       "26                  Yes\n",
       "27                  Yes\n",
       "28                  Yes\n",
       "29                  Yes\n",
       "..                  ...\n",
       "425                 Yes\n",
       "426                  No\n",
       "427                 Yes\n",
       "428                  No\n",
       "429                  No\n",
       "430                 NaN\n",
       "431                 Yes\n",
       "432                 Yes\n",
       "433                 Yes\n",
       "434                  No\n",
       "435                  No\n",
       "436                 Yes\n",
       "437                  No\n",
       "438                  No\n",
       "439                 Yes\n",
       "440                  No\n",
       "441                 Yes\n",
       "442                 Yes\n",
       "443                  No\n",
       "444                  No\n",
       "445                 Yes\n",
       "446                 Yes\n",
       "447                 Yes\n",
       "448                 Yes\n",
       "449                  No\n",
       "450                 Yes\n",
       "451                 Yes\n",
       "452                  No\n",
       "453                  No\n",
       "454                 Yes\n",
       "\n",
       "[455 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRP[[\"Q3 (Student Author)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the AISTATS2021 Proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary containing papers as dictionaries. Each paper must consist of\n",
    "# (1) title \n",
    "# (2) author (lastname, firstnames format separated by 'and') \n",
    "# (3) pages in “startpage–endpage” format\n",
    "# (4) abstract\n",
    "papers = {} \n",
    "identifiers = {}\n",
    "\n",
    "pages_count = 1\n",
    "num_pages = 9\n",
    "YY = '21'\n",
    "for index, row in CRP.iterrows():\n",
    "    \n",
    "    # read the paper information (paper id, title, authors, and abstract)\n",
    "    paper_id = row['Paper ID']\n",
    "    title    = row['Paper Title'].strip()\n",
    "    authors  = row['Author Names'].strip()\n",
    "    abstract = row['Abstract'].strip()\n",
    "    files    = row['Files'].strip()\n",
    "    \n",
    "    # remove the newline character in the abstract\n",
    "    abstract = \" \".join(abstract.split())\n",
    "    \n",
    "    # extract filenames\n",
    "    flist = list(filter(None,re.split(r'\\(.*?bytes\\);?',files)))\n",
    "    flist = [f.strip() for f in flist]\n",
    "    \n",
    "    # preprocess the author names and extract the identifier (author's lastname) \n",
    "    alist = list(filter(None,re.split(r'\\(.*?\\)\\*?;?', authors)))\n",
    "    alist = [a.strip() for a in alist]\n",
    "    \n",
    "    first_author_lastname = alist[0].split()[-1]\n",
    "    paper_key = first_author_lastname + YY\n",
    "    if first_author_lastname in identifiers:\n",
    "        paper_key += chr(ord('a')+identifiers[first_author_lastname])\n",
    "        identifiers[first_author_lastname] += 1 \n",
    "    else:\n",
    "        identifiers[first_author_lastname] = 1\n",
    "        \n",
    "    # format the author list\n",
    "    new_alist = []\n",
    "    for i in range(len(alist)):  \n",
    "        new_alist.append(', '.join([' '.join(alist[i].split()[1:]), alist[i].split()[0]]))\n",
    "    author_list = ' and '.join(new_alist)\n",
    "        \n",
    "    # add the paper to the dictionary\n",
    "    papers[paper_key] = {'key': paper_key,\n",
    "                         'id': paper_id, \n",
    "                         'title': title, \n",
    "                         'authors': author_list,\n",
    "                         'files': flist,\n",
    "                         'pages':'{}-{}'.format(pages_count,pages_count+num_pages-1), \n",
    "                         'abstract': abstract} \n",
    "    pages_count += num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 4096, Number of papers: 455.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of pages: {}, Number of papers: {}'.format(pages_count,(pages_count-1)/num_pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file(src, dest):\n",
    "    try:\n",
    "        copyfile(src, dest)\n",
    "    except Error as err: \n",
    "        errors.extend(err.args[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_papers = {}\n",
    "form_not_found = 'permission form not found.'\n",
    "main_not_found = 'main paper not found.'\n",
    "supp_not_found = 'supplementary file may not exist.'\n",
    "multiple_supps = 'multiple supplementary files.'\n",
    "\n",
    "for iden in papers:\n",
    "    paper_id   = papers[iden]['id']\n",
    "    main_paper = '{}.pdf'.format(paper_id)\n",
    "    supplement = '{}-supp'.format(paper_id)\n",
    "    perm_form  = '{}-Permission.pdf'.format(paper_id)\n",
    "    \n",
    "    # process main paper\n",
    "    if main_paper in papers[iden]['files']:\n",
    "        org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,main_paper))\n",
    "    else:\n",
    "        potential_main = [mf for mf in papers[iden]['files'] \n",
    "                          if any(subt for subt in ['main','camera','ready'] if subt in mf.lower())]\n",
    "        if any(potential_main):\n",
    "            org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,potential_main[0]))\n",
    "        else:\n",
    "            problematic_papers[iden] = main_not_found\n",
    "            continue\n",
    "    \n",
    "    dest_file = os.path.join(dest_pdf_folder,'{}.pdf'.format(iden))\n",
    "    copy_file(org_file, dest_file)\n",
    "    \n",
    "    # process permission form\n",
    "    if perm_form in papers[iden]['files']:\n",
    "        org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,perm_form))\n",
    "    else:\n",
    "        potential_form = [pf for pf in papers[iden]['files'] \n",
    "                          if any(subt for subt in ['permission','pmlr','agreement','license'] if subt in pf.lower())]\n",
    "        if any(potential_form):\n",
    "            org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,potential_form[0]))\n",
    "        else:\n",
    "            problematic_papers[iden] = form_not_found\n",
    "            continue\n",
    "        \n",
    "    dest_file = os.path.join(dest_pdf_folder,'{}-Permission.pdf'.format(iden))\n",
    "    copy_file(org_file, dest_file)\n",
    "        \n",
    "    # process supplementary file\n",
    "    supplement_file = [sf for sf in papers[iden]['files'] if supplement in sf]\n",
    "    if any(supplement_file):\n",
    "        if len(supplement_file) == 1:\n",
    "            supplement_file = supplement_file[0]\n",
    "            supp_ext = os.path.splitext(supplement_file)[1]\n",
    "            org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,supplement_file))\n",
    "        else:\n",
    "            problematic_papers[iden] = multiple_supps\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        potential_supp = [ps for ps in papers[iden]['files'] \n",
    "                          if any(subt for subt in ['sup','supp','supplementary','appendix'] if subt in ps.lower())]\n",
    "        \n",
    "        if any(potential_supp):\n",
    "            supp_ext = os.path.splitext(potential_supp[0])[1]\n",
    "            org_file  = os.path.join(org_pdf_folder,'{}\\CameraReady\\{}'.format(paper_id,potential_supp[0]))    \n",
    "        else:\n",
    "            problematic_papers[iden] = supp_not_found\n",
    "            continue\n",
    "    \n",
    "    dest_file = os.path.join(dest_pdf_folder,'{}-supp{}'.format(iden,supp_ext))\n",
    "    copy_file(org_file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problematic papers: 36\n",
      "No permission form: 7\n",
      "No main paper: 0\n",
      "No supplementary: 29\n",
      "Multiple supplements: 0\n"
     ]
    }
   ],
   "source": [
    "no_permission_form = [p for p in problematic_papers if problematic_papers[p] == form_not_found]\n",
    "no_main_paper      = [p for p in problematic_papers if problematic_papers[p] == main_not_found]\n",
    "no_supplement      = [p for p in problematic_papers if problematic_papers[p] == supp_not_found]\n",
    "multiple_supps     = [p for p in problematic_papers if problematic_papers[p] == multiple_supps]\n",
    "\n",
    "print('Number of problematic papers: {}'.format(len(problematic_papers)))\n",
    "print('No permission form: {}'.format(len(no_permission_form)))\n",
    "print('No main paper: {}'.format(len(no_main_paper)))\n",
    "print('No supplementary: {}'.format(len(no_supplement)))\n",
    "print('Multiple supplements: {}'.format(len(multiple_supps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[papers[key]['id'] for key in no_main_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[339, 420, 434, 690, 1118, 1165, 1342]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[papers[key]['id'] for key in no_permission_form]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50,\n",
       " 76,\n",
       " 208,\n",
       " 292,\n",
       " 312,\n",
       " 344,\n",
       " 406,\n",
       " 547,\n",
       " 684,\n",
       " 796,\n",
       " 799,\n",
       " 975,\n",
       " 1058,\n",
       " 1062,\n",
       " 1068,\n",
       " 1090,\n",
       " 1159,\n",
       " 1194,\n",
       " 1205,\n",
       " 1233,\n",
       " 1240,\n",
       " 1365,\n",
       " 1436,\n",
       " 1445,\n",
       " 1467,\n",
       " 1565,\n",
       " 1581,\n",
       " 1584,\n",
       " 1671]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[papers[key]['id'] for key in no_supplement]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the bibtex file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loader = FileSystemLoader('templates')\n",
    "env = Environment(loader=file_loader)\n",
    "template = env.get_template('bibtex_template.txt')\n",
    "aistats21_bibtex = template.render(papers=papers)\n",
    "\n",
    "f = open('aistats21.bib','w')\n",
    "f.write(aistats21_bibtex)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
